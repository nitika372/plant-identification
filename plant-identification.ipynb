{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-26T04:24:29.489756Z",
     "iopub.status.busy": "2024-10-26T04:24:29.489238Z",
     "iopub.status.idle": "2024-10-26T04:24:29.842597Z",
     "shell.execute_reply": "2024-10-26T04:24:29.841697Z",
     "shell.execute_reply.started": "2024-10-26T04:24:29.489721Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:24:34.614281Z",
     "iopub.status.busy": "2024-10-26T04:24:34.613745Z",
     "iopub.status.idle": "2024-10-26T04:24:34.701230Z",
     "shell.execute_reply": "2024-10-26T04:24:34.700299Z",
     "shell.execute_reply.started": "2024-10-26T04:24:34.614235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set 1\n",
      "Number of images in test set 1\n",
      "Number of images in val set 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def total_files(folder_path):\n",
    "    num_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "    return num_files\n",
    "\n",
    "train_files = \"/kaggle/input/plants-classification/train\"\n",
    "test_files = \"/kaggle/input/plants-classification/test\"\n",
    "valid_files = \"/kaggle/input/plants-classification/val\"\n",
    "\n",
    "\n",
    "print(\"Number of images in training set\", total_files(train_files))\n",
    "print(\"Number of images in test set\", total_files(test_files))\n",
    "print(\"Number of images in val set\", total_files(valid_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:24:36.894112Z",
     "iopub.status.busy": "2024-10-26T04:24:36.893742Z",
     "iopub.status.idle": "2024-10-26T04:24:36.911723Z",
     "shell.execute_reply": "2024-10-26T04:24:36.910906Z",
     "shell.execute_reply.started": "2024-10-26T04:24:36.894074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxMSEhISEhISFhIWFxcYFxUVFhIVFRUXFRUXFxgVFRYYHSggGBolGxUWITEhJykrLi4uGB8zODMsNygtLisBCgoKDg0OGxAQGjcmHiYtLysxNS0rLS4wLTYtLS0tNS8vNS0tNSstMDAtLS0vKy0tLS0tKy0tLystLS8tLSsvLf/AABEIAOEA4QMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAgUDBAYBB//EADYQAAIBAgQEBAUDBAEFAAAAAAABAgMRBCExQQUSUWFxgZGhBiKx0fATweEyUmLxQhRDcoKi/8QAGgEBAAMBAQEAAAAAAAAAAAAAAAIDBAEFBv/EAC4RAAICAQMCBQMCBwAAAAAAAAABAgMRBCExEkETIlFhgQUy8KHhFBVxkbHB0f/aAAwDAQACEQMRAD8A+4gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHjYB6DUq45L+nP6GnPFSlvl0WXh+5ls1dcduSyNcmWkqiWrRjeKh/cvcqf477bk7fnn9TO9dJ8Is8Fd2Wf/Vw6+zJLEw/uXrYp79Nevf8AfxI3VvTTPorJoh/MJeh3wEX0ZX0PTnp1uXNtR87PbXPxMtHjUVk5xl5r6+BbD6jXnE9iDpfYvAYcNiYzV4szG+MlJZT2KWsAAHQAAAAAAAAAAAAAAAAAAAAAADBi8QoK++338DkpKKyzqWdkSr4hRWeuy3KutiXN726LTz9dzXrVW27t33006oi3d38M8tNn4Z9Dx9Rq5TeFwa4VKO7MienTz83nt9vWUV+/r69LEOry0zTslrrnff8AMs/HN/5Zb2zeejttncx9ST3LMehPnWSy18NrK2X5fsQqVvlu7W/y+Vf/AFou3Y0cXxJU7xj80k7ZvLXVvVvJFTVlOo7ybf50KJXN7L8/PzBCU4xLTFcaisoLmfV5LbbV6dirr46rU1k0uiyXtqThhkZlSsQalL7mUObZXOg3mzHPDst3TPJUyPQlwQ3KvC4upSlzRk1Y73gfFFXhfSaykvo12OJxFM3/AIPr8tfl/uTXpn+xq0N7qtUc7N4fz+53lHcgA+nKwAAAAAAAAAAAAAAAAAAAACNSaSbeiOexeJc3d6aLXLz2/wBm/wAbxDSjBb5uzzS29/oU1753v2Vt9s/LU8rXXNvoj2Nenr26mZk/T2z18rP+T1Pb2bd8nnb3zZFNbe1+q6ZrZCU8ndu27urrrn2z0PMnszQSdXLXJXbzVt7tu3W68yrxmPcnyw00b3aX0MeKxDqO2fKtO/d9We0aNjPlz54M9lnaJjp0DahTRKKPJTsT2RUo5JJEZSRo4niMYXu9Clx/xJCCbbdlvZ9VHLrmytzy8IvhRKXCOldREXUOWXxJDKKbbeemxKXGZZKMW5PSKzb8ivMs8Ep6eUVll5iaiszkqPxBXjibYaDnNO17NqO12dPgOD1a2dV8sf7Vr/7S+xf4Th9KguWEYrwX2NEIY80jKsqWxc8I4i5U4Krf9SyUnbJu9k9tctlmy0ORr1dLbd9/y3qdRg63PCMuqz8dH7nvaHUu1OL7HbK3Hf1MwAN5SAAAAAAAAAAAAAAAAAAczxOpzVJXzs7JeHTv2NaPhnlss7q7ffK+fj4katS7bbte/jn+f6uST2X79bWa8n2uz5uyXVNyPUisRSMkXpp7Wzdt9cnmaOMrc1oq1l0Szfppp6GbFVLLlWumStbrbp9DXhAxTfU/YptnjyoUqZkZCVSxzHxD8UwpfLBqU+ZJrp4k1l7IrhW5PYvsbxGFOLlKSSWrbsl5nMcW+JJRhLkjaTfJBz05mnZ5anFzqVMUnKtObipTThmlG0ZS08bexb8OpSqUqVNN2sua7bXy58yvnfItlT04y8s9CqiKWZGphqtf9WtWru9RuNPlWi+S65NUlaXqyeLk0nF83JbLmVrtatvK1y+jh40m4xi6labuoq7d7JfsuyLjhXwbOtJVcY0+lOOUI+LWpYl1SzglK+Na9jivhzhuMxbXJFU6Ssuezba/xk9T6nwH4bp4eO7erbzlJ9Wyxp8lJKMEkkrKysl27GKpXbt5eHlvsV23Vp7LL/T9zHJ2Xc7I3KuISXLHL899/Q1JVL738UrZ9vAwuXovT09SKfXL9/TTy6eRV1OT8xOMIxWx7KXjbK38LzOi+H53pW6Sa+j/AHOYnPs/Tv8AnsdD8MyvTl/5duiPS+nvFvwU6heQuQAe4YgAAAAAAAAAAAAAAAeSPQAcY0+nvb/az27k00l2t0TX40tdPEniYcs5Lu/r1/0a+JlaL75LbJ5u3TRep8tc3FNfB6eV05MEpXbZGdRIxOqkaOOxSUXd5JbmPqwsGWK6mUvxNx7lapxdua92nmrJv3scLh8C5zi51JaKUZPPmVouLzvdtcyu90bGJoVKk3GrOF7uULcybz0usks2l+IveBfA1aso8ynClFvlc5O9mv8AjFWerdrteB6dUVXHndnpLw4JZ7FTRxCcm4u0Gle6teSaWSSzTsvWx2nAeCYmta6VKlbXNza/xuly67oveFfD2Gwijk5zirJzbk1bKyvobeI4m3/Tks+19ymy6qD9/T/pVO6dn2L5f+jYwWBoYZfKlzbyebdusnqeVse20trvqtCtdW+cvHfr3sZeZt2u32z2yTS0WZQ7ZWLHCK41JPL3ZmdXwvtp1t6XJKXfp3W2v8mHOyzt4aP1een1Ja/vrfvmt7r8ZyMcFjZljLK+j8srb9FqvQi5d/bO3ZXvt9SClv6emV9LPXffueTfivbcm2jmCFR32+v7a7nUfDFO1G/WT9rL9jlL3/Pz8sd1w6jyUoR3Sz8Xm/dno/TF1WOXoijUvEcGyARnNJXeh7nBhJA1njYmGrxSMdit3QSy2DfBp4DiUK11C/y63WWfc3DsLIzj1ReUdawAATOAAAAAAAAAHO8ap2qPo0nfps/oUnFZ8qgtszrON4fmhzLWP0ZxXHMNVqqCp8urV20uVfLa/U+a+o1uNrx33N0H1VFNjOIJMjR4XWxKs/kg9XrK3bZe5dcL+HIU/mm+efXbyLnmsmlku3TqYElHc5Cqf9Cu4Z8P4fD5qEebVuyv5tllLE3ds0u2u3t9jBWfhl/PTO+/gMMvmfg9c3qumx1ynJ4/Pkv8Jcvdm1PhcJZupJ+n2J0+G0Vqm+/NL75mvGs1uZIVbm2pVS3UUYpWT4bNHi2B/SfPD+h+qb0XgV8anW3nba2fZ6HTr5ouMtGrM5XiODnRlnnB/wBMrZa6Pv2IamjofVDj/Bpot6lh8mx+orPTwaS8l0036mSNT6/V+On0K39fX+MvuTjXsvz1/nuzJ4hp6TddTpb8WeWvT3IOfS3v1/jXsazxHe/dPy2J0p3f51IttncYLXgeG/UqxVsl8z00Wz87I7YoOCclGneT+eVnZZtLZdupmr8TlLKC5V13/g97SWV6anzPzPfC5POuzOW3BaVq6jq/Lcq8TjHLsuhpxb1bd+55KRKWpnauML0KWkiM6ppYurc2qhX15GPUJqOCOToPhSjak3/dL6L/AGXZo8Fp8tGC7X9Xde1jePZ0dfh0Qj7HZPLAANJEAAAAAAAAA8lG6aehyvE8FySaz5Xmn1Szz8zqzBjMMqkeV+T6MyazTK+GO5dTb4cvY5iMsk+ztr9O7ueyXRdHo/2Wn5kTq0ZUpcssr7rR9/oQvo8r3Xn2WeWVkeF042lyb+d1wYJw8/K637bL2I0Mp6a5adb5+t8u5lcd/fd2b720ijFU65vTXx8ddiiTS3LEsmTEdfz8+xGEjPK047eN1r0VvA06fQvrliWDz74YeSxpTNhNNOMkmnqnmmV9KZsRZ6UGmjPk0q/wzRk7wnOHZNNeV1da9TBH4US/7ra8EvuXEahP9QrlpaZb4LlqLF3Kyn8NU1m5N+L+xvUeG046WXgjLznnMR/hK12Dvm+WP00j25ByPHInGqMeCDk2etmNnrZjmyeEtyDZjryNNRcpJLVtL1MlWoWHw7heapzvSP1en3MjXjWKCOx9TpKUOWKitEkvQmAfQJYIgAHQAAAAAAAAAAAAY69CM1yySaKLGcInC7p3lHplzL7nQkKlRLNsz36au1ebn1La7ZQ4OOc7Xys908tXp7L0PG9fou/TL8zL7H1Kc9aab2byfk1mUtbB9G14528DwrtHKL8ryelVYpcrBjpVeV22z7W79v5M9alfNffK/X08TTnhZbNe5lwvPHKSTj4ttb5ZWKoVzXlaO2wjNEYuxmhVue1aV9DVzRdC5x2Z5k6nE3ozJqZXqqZYVe5pVyKjcchzGqqx7+sifiIGdyHMYFUR5KZxzSBnlI1qlW5CdQU4OTSirt7FE7s7I6kKdJzkoxV2zr8BhVTgorzfVmtwrhypK7/revbsixPR0emda65cv9DrfYAA3kQAAAAAAAAAAAAAACM2aVWm3qbzRFxONZOp4K2WHMcsMWrgQlAqdMWWK2SKiWFMcsOW06RhlRKpUIsjcysdE16uH8/r6ltLDkHhmZbdKp8osVi7nO1KDT0f7kb2Ohlhn0MbwF/+Jjehsj9r/uRlCt8PBR84jMuVwW//ABMkeA+XmFpdR6FThFdyk5z2Lb0OipcCgtTbpcNhHYtjoLpPdpEfIu5Q4XhE5/1fKu+voXuDwcaa+VZ7vdm3CmloTPRo0cKt+WRb9DGoskokgayIAAAAAAAAAAAAAAAAAAAAAPLHoAPLHnKiQAI8o5USABHlR7Y9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABScXrpVHz041IqKsp35U25c0rcrWnKrvo0nqVscU6lCvTbi4JwUc5TUU6i+TmheTkrrl0lkslk5QVibwR6t8HWg+c1v0nyqrOhGalH/AJYp/LJKMeWF05WUbc2mcc3fO/8AhjEYamoxjUi6tSylGDnOPN80ko5ZKzk7XsuWX9rJkjpwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY50IuSk4ptaN528CU6aacWk09tiQOYBgWFh076vXr45v1MkKSWiRMHcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/jpeg": {
       "width": 500
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "image_path = '/kaggle/input/plants-classification/train/cantaloupe/cantaloupe0.jpg'\n",
    "\n",
    "with open(image_path, 'rb') as f:\n",
    "    display.display(display.Image(data=f.read(), width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:25:09.946450Z",
     "iopub.status.busy": "2024-10-26T04:25:09.946056Z",
     "iopub.status.idle": "2024-10-26T04:25:09.951422Z",
     "shell.execute_reply": "2024-10-26T04:25:09.950333Z",
     "shell.execute_reply.started": "2024-10-26T04:25:09.946412Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:25:11.107575Z",
     "iopub.status.busy": "2024-10-26T04:25:11.107249Z",
     "iopub.status.idle": "2024-10-26T04:25:11.112647Z",
     "shell.execute_reply": "2024-10-26T04:25:11.111762Z",
     "shell.execute_reply.started": "2024-10-26T04:25:11.107542Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:42:13.895117Z",
     "iopub.status.busy": "2024-10-26T04:42:13.894197Z",
     "iopub.status.idle": "2024-10-26T04:42:16.719031Z",
     "shell.execute_reply": "2024-10-26T04:42:16.718312Z",
     "shell.execute_reply.started": "2024-10-26T04:42:13.895076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21000 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/plants-classification/train',\n",
    "                                                    target_size=(225, 225),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:42:16.720959Z",
     "iopub.status.busy": "2024-10-26T04:42:16.720623Z",
     "iopub.status.idle": "2024-10-26T04:42:17.600150Z",
     "shell.execute_reply": "2024-10-26T04:42:17.599374Z",
     "shell.execute_reply.started": "2024-10-26T04:42:16.720923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory('/kaggle/input/plants-classification/test',\n",
    "                                                        target_size=(225, 225),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:42:17.602317Z",
     "iopub.status.busy": "2024-10-26T04:42:17.601469Z",
     "iopub.status.idle": "2024-10-26T04:42:18.521259Z",
     "shell.execute_reply": "2024-10-26T04:42:18.520416Z",
     "shell.execute_reply.started": "2024-10-26T04:42:17.602270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(225, 225, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(30, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:42:18.523317Z",
     "iopub.status.busy": "2024-10-26T04:42:18.523011Z",
     "iopub.status.idle": "2024-10-26T04:42:18.536200Z",
     "shell.execute_reply": "2024-10-26T04:42:18.535193Z",
     "shell.execute_reply.started": "2024-10-26T04:42:18.523285Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T04:42:19.688091Z",
     "iopub.status.busy": "2024-10-26T04:42:19.687370Z",
     "iopub.status.idle": "2024-10-26T06:15:39.710981Z",
     "shell.execute_reply": "2024-10-26T06:15:39.710200Z",
     "shell.execute_reply.started": "2024-10-26T04:42:19.688053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729917747.414424     120 service.cc:145] XLA service 0x7c0e20005330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729917747.414493     120 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1729917747.414499     120 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/657\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58:52\u001b[0m 11s/step - accuracy: 0.0625 - loss: 3.4143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729917751.886558     120 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 671ms/step - accuracy: 0.1495 - loss: 3.1883 - val_accuracy: 0.3377 - val_loss: 2.3095\n",
      "Epoch 2/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 407ms/step - accuracy: 0.3411 - loss: 2.2435 - val_accuracy: 0.3777 - val_loss: 2.1411\n",
      "Epoch 3/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 413ms/step - accuracy: 0.4214 - loss: 1.9684 - val_accuracy: 0.4533 - val_loss: 1.9264\n",
      "Epoch 4/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 409ms/step - accuracy: 0.4851 - loss: 1.7618 - val_accuracy: 0.4775 - val_loss: 1.8929\n",
      "Epoch 5/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 409ms/step - accuracy: 0.5335 - loss: 1.5811 - val_accuracy: 0.5053 - val_loss: 1.7913\n",
      "Epoch 6/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 407ms/step - accuracy: 0.5748 - loss: 1.4349 - val_accuracy: 0.5308 - val_loss: 1.7426\n",
      "Epoch 7/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 408ms/step - accuracy: 0.6205 - loss: 1.2765 - val_accuracy: 0.5483 - val_loss: 1.7339\n",
      "Epoch 8/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 406ms/step - accuracy: 0.6383 - loss: 1.1982 - val_accuracy: 0.5388 - val_loss: 1.7841\n",
      "Epoch 9/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 407ms/step - accuracy: 0.6811 - loss: 1.0747 - val_accuracy: 0.5422 - val_loss: 1.8846\n",
      "Epoch 10/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 408ms/step - accuracy: 0.6948 - loss: 0.9933 - val_accuracy: 0.5640 - val_loss: 1.8366\n",
      "Epoch 11/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 409ms/step - accuracy: 0.7053 - loss: 0.9592 - val_accuracy: 0.5547 - val_loss: 2.0267\n",
      "Epoch 12/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 408ms/step - accuracy: 0.7335 - loss: 0.8709 - val_accuracy: 0.5740 - val_loss: 1.8945\n",
      "Epoch 13/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 410ms/step - accuracy: 0.7470 - loss: 0.8289 - val_accuracy: 0.5643 - val_loss: 2.0417\n",
      "Epoch 14/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 408ms/step - accuracy: 0.7686 - loss: 0.7548 - val_accuracy: 0.5887 - val_loss: 1.9635\n",
      "Epoch 15/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 406ms/step - accuracy: 0.7644 - loss: 0.7420 - val_accuracy: 0.5933 - val_loss: 1.9876\n",
      "Epoch 16/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 407ms/step - accuracy: 0.7846 - loss: 0.6893 - val_accuracy: 0.5753 - val_loss: 2.1544\n",
      "Epoch 17/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 408ms/step - accuracy: 0.7867 - loss: 0.6783 - val_accuracy: 0.5975 - val_loss: 1.9826\n",
      "Epoch 18/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 407ms/step - accuracy: 0.8061 - loss: 0.6162 - val_accuracy: 0.5837 - val_loss: 2.2593\n",
      "Epoch 19/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 409ms/step - accuracy: 0.8069 - loss: 0.6007 - val_accuracy: 0.5880 - val_loss: 2.2658\n",
      "Epoch 20/20\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 409ms/step - accuracy: 0.8192 - loss: 0.5608 - val_accuracy: 0.5862 - val_loss: 2.2764\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    batch_size=16,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_batch_size=16\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:01:17.959877Z",
     "iopub.status.busy": "2024-10-26T07:01:17.959565Z",
     "iopub.status.idle": "2024-10-26T07:25:29.473546Z",
     "shell.execute_reply": "2024-10-26T07:25:29.472617Z",
     "shell.execute_reply.started": "2024-10-26T07:01:17.959844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 419ms/step - accuracy: 0.8683 - loss: 0.3850 - val_accuracy: 0.6153 - val_loss: 2.6403\n",
      "Epoch 2/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 414ms/step - accuracy: 0.8715 - loss: 0.3851 - val_accuracy: 0.6227 - val_loss: 2.6152\n",
      "Epoch 3/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 454ms/step - accuracy: 0.8710 - loss: 0.3626 - val_accuracy: 0.6162 - val_loss: 2.5537\n",
      "Epoch 4/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 457ms/step - accuracy: 0.8711 - loss: 0.3807 - val_accuracy: 0.6185 - val_loss: 2.8495\n",
      "Epoch 5/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 443ms/step - accuracy: 0.8751 - loss: 0.3586 - val_accuracy: 0.6213 - val_loss: 2.6651\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    batch_size=16,\n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_batch_size=16\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T06:38:40.734842Z",
     "iopub.status.busy": "2024-10-26T06:38:40.734567Z",
     "iopub.status.idle": "2024-10-26T06:38:41.055476Z",
     "shell.execute_reply": "2024-10-26T06:38:41.054420Z",
     "shell.execute_reply.started": "2024-10-26T06:38:40.734811Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('plant_ident.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3922585,
     "sourceId": 6819972,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
